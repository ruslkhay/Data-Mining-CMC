{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LassoLars, LassoLarsCV, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "enable_halving_search_cv\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Sub-task 1.\n",
    "\n",
    "The file \"domations.csv\" contains a sample of information about participants in the program of\n",
    "donating money to the needs of veterans' organizations. Each record is one person from the\n",
    "mailing list. He has socio-demographic characteristics (gender, age, median\n",
    "income in the area of ​​his residence, whether he is a homeowner, etc., etc.),\n",
    "behavioral characteristics (aggregated characteristics of his early donations such as\n",
    "GiftCount36 - the number of donations over three years, GiftAmntLast - the amount of the last\n",
    "donation, PromCntCard12 - the number of contacts with him over the year as part of an advertising campaign,\n",
    "etc.). There are also two responses: the TargetB flag (whether he donated or not) and TargetD - the\n",
    "donation amount (skip if he did not donate, otherwise the amount in dollars). As part of the first part\n",
    "of the task, you need to build regression models (only for people who donated money),\n",
    "explaining and predicting the donation amount TargetD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the donations dataset\n",
    "data = pd.read_csv(\"../data/donations.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nData Types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Let's see the first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "\n",
    "# Since we're only interested in records where people donated,\n",
    "# filter the dataset for records where TargetB == 1 (donated)\n",
    "donors = data[data[\"TargetB\"] == 1].copy()\n",
    "print(f\"\\nNumber of donors: {donors.shape[0]}\")\n",
    "print(f\"Number of non-donors: {data[data['TargetB'] == 0].shape[0]}\")\n",
    "\n",
    "# Check the distribution of the target variable (TargetD - donation amount)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(donors[\"TargetD\"], kde=True)\n",
    "plt.title(\"Distribution of Donation Amounts (TargetD)\")\n",
    "plt.xlabel(\"Donation Amount ($)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Check if there are any missing values in the donation amount column\n",
    "print(f\"\\nMissing values in TargetD for donors: {donors['TargetD'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Sub-task 2.\n",
    "\n",
    "Select and save as a holdout 30% of the original sample stratified by response. Note that the response is continuous and needs to be discretized. Choose the number of intervals and the discretization method yourself. Build and visualize a histogram (or kde approximation) for the response distribution in the entire original set, in the holdout, and in the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, discretize the continuous response variable (TargetD) for stratification\n",
    "# We'll use 5 bins (quantiles) for discretization\n",
    "donors[\"TargetD_bins\"] = pd.qcut(donors[\"TargetD\"], q=5, labels=False)\n",
    "\n",
    "# Split the data into train and holdout sets (70% train, 30% holdout)\n",
    "train_data, holdout_data = train_test_split(\n",
    "    donors,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=donors[\"TargetD_bins\"],  # Stratify by the binned donation amount\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {train_data.shape[0]} records\")\n",
    "print(f\"Holdout set size: {holdout_data.shape[0]} records\")\n",
    "\n",
    "# Visualize the distribution of TargetD in the original, training, and holdout sets\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot for the entire dataset\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(donors[\"TargetD\"], kde=True, color=\"blue\")\n",
    "plt.title(\"Donation Distribution - Full Dataset\")\n",
    "plt.xlabel(\"Donation Amount ($)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot for the training set\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(train_data[\"TargetD\"], kde=True, color=\"green\")\n",
    "plt.title(\"Donation Distribution - Training Set\")\n",
    "plt.xlabel(\"Donation Amount ($)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot for the holdout set\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(holdout_data[\"TargetD\"], kde=True, color=\"red\")\n",
    "plt.title(\"Donation Distribution - Holdout Set\")\n",
    "plt.xlabel(\"Donation Amount ($)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Let's also compare KDE approximations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(donors[\"TargetD\"], label=\"Full Dataset\", color=\"blue\")\n",
    "sns.kdeplot(train_data[\"TargetD\"], label=\"Training Set\", color=\"green\")\n",
    "sns.kdeplot(holdout_data[\"TargetD\"], label=\"Holdout Set\", color=\"red\")\n",
    "plt.title(\"KDE Approximation of Donation Distributions\")\n",
    "plt.xlabel(\"Donation Amount ($)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Sub-task 3.\n",
    "\n",
    "At the data preprocessing stage, perform missing imputation using the KnnImputer (neighbors=7) method, preserving binary features about which variables were imputed. Transformations of categorical variables using WOE, Target encoding, Threshold\n",
    "encoding and other methods, as well as transformation of numerical variables (to obtain more symmetrical distributions using log or Box-Cox) are encouraged, but not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature types\n",
    "numeric_features = [\n",
    "    col for col in train_data.columns if train_data[col].dtype in [\"int64\", \"float64\"]\n",
    "]\n",
    "numeric_features = [\n",
    "    col\n",
    "    for col in numeric_features\n",
    "    if col not in [\"TargetB\", \"TargetD\", \"TargetD_bins\", \"ID\"]\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    col for col in train_data.columns if train_data[col].dtype == \"object\"\n",
    "]\n",
    "\n",
    "print(f\"Number of numeric features: {len(numeric_features)}\")\n",
    "print(f\"Number of categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# 3a. Missing Value Imputation with KnnImputer and creating binary flags\n",
    "# Create binary indicators for missing values before imputation\n",
    "for feature in numeric_features + categorical_features:\n",
    "    if train_data[feature].isnull().sum() > 0:\n",
    "        train_data[f\"{feature}_missing\"] = train_data[feature].isnull().astype(int)\n",
    "        holdout_data[f\"{feature}_missing\"] = holdout_data[feature].isnull().astype(int)\n",
    "\n",
    "# Impute missing values in numeric features using KnnImputer\n",
    "# First, let's separate the target variable and keep track of it\n",
    "X_train = train_data[numeric_features].copy()\n",
    "y_train = train_data[\"TargetD\"].copy()\n",
    "X_holdout = holdout_data[numeric_features].copy()\n",
    "y_holdout = holdout_data[\"TargetD\"].copy()\n",
    "\n",
    "# Initialize and fit the KNN imputer\n",
    "imputer = KNNImputer(n_neighbors=7)\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_holdout_imputed = imputer.transform(X_holdout)\n",
    "\n",
    "# Convert back to DataFrames\n",
    "X_train_imputed = pd.DataFrame(\n",
    "    X_train_imputed, columns=numeric_features, index=X_train.index\n",
    ")\n",
    "X_holdout_imputed = pd.DataFrame(\n",
    "    X_holdout_imputed, columns=numeric_features, index=X_holdout.index\n",
    ")\n",
    "\n",
    "# Merge the imputed numeric features with the binary missing indicators and categorical features\n",
    "for col in X_train_imputed.columns:\n",
    "    train_data[col] = X_train_imputed[col]\n",
    "    holdout_data[col] = X_holdout_imputed[col]\n",
    "\n",
    "# 3b. Transform numeric variables to make them more symmetrical\n",
    "# Check for skewness in numeric features\n",
    "skewed_features = []\n",
    "for feature in numeric_features:\n",
    "    skewness = train_data[feature].skew()\n",
    "    if abs(skewness) > 1:  # Threshold for considering a feature as skewed\n",
    "        skewed_features.append(feature)\n",
    "\n",
    "print(f\"Number of skewed numeric features: {len(skewed_features)}\")\n",
    "\n",
    "# Apply Box-Cox transformation to skewed features\n",
    "for feature in skewed_features:\n",
    "    # Make sure all values are positive for Box-Cox\n",
    "    if min(train_data[feature]) <= 0:\n",
    "        train_data[f\"{feature}_bc\"] = np.log1p(\n",
    "            train_data[feature] - min(train_data[feature]) + 1\n",
    "        )\n",
    "        holdout_data[f\"{feature}_bc\"] = np.log1p(\n",
    "            holdout_data[feature] - min(train_data[feature]) + 1\n",
    "        )\n",
    "    else:\n",
    "        # Use PowerTransformer with method='box-cox'\n",
    "        pt = PowerTransformer(method=\"box-cox\")\n",
    "        train_data[f\"{feature}_bc\"] = pt.fit_transform(train_data[[feature]])\n",
    "        holdout_data[f\"{feature}_bc\"] = pt.transform(holdout_data[[feature]])\n",
    "\n",
    "# 3c. Target Encoding for categorical variables\n",
    "# For each categorical feature, replace the category with the mean of the target variable for that category\n",
    "for feature in categorical_features:\n",
    "    # Dictionary to map categories to their average target value\n",
    "    target_means = train_data.groupby(feature)[\"TargetD\"].mean().to_dict()\n",
    "\n",
    "    # Apply the encoding\n",
    "    train_data[f\"{feature}_target_enc\"] = train_data[feature].map(target_means)\n",
    "    holdout_data[f\"{feature}_target_enc\"] = holdout_data[feature].map(target_means)\n",
    "\n",
    "    # Handle new categories in the holdout set by using the overall mean\n",
    "    holdout_data[f\"{feature}_target_enc\"].fillna(\n",
    "        train_data[\"TargetD\"].mean(), inplace=True\n",
    "    )\n",
    "\n",
    "# 3d. Threshold Encoding for categorical variables\n",
    "# For each categorical feature, create a binary variable indicating if the category is above a certain threshold\n",
    "for feature in categorical_features:\n",
    "    # Get the mean target value for each category\n",
    "    category_means = train_data.groupby(feature)[\"TargetD\"].mean()\n",
    "\n",
    "    # Define the threshold as the median of the category means\n",
    "    threshold = category_means.median()\n",
    "\n",
    "    # Create a binary variable where 1 means the category's mean target is above the threshold\n",
    "    train_data[f\"{feature}_threshold_enc\"] = train_data[feature].map(\n",
    "        category_means.gt(threshold).astype(int)\n",
    "    )\n",
    "    holdout_data[f\"{feature}_threshold_enc\"] = holdout_data[feature].map(\n",
    "        category_means.gt(threshold).astype(int)\n",
    "    )\n",
    "\n",
    "    # Handle new categories in the holdout set\n",
    "    holdout_data[f\"{feature}_threshold_enc\"].fillna(0, inplace=True)\n",
    "\n",
    "# Now we have preprocessed our datasets with imputation, binary flags for missing values,\n",
    "# and transformed numeric and categorical features\n",
    "print(\"\\nPreprocessed Training Dataset Shape:\", train_data.shape)\n",
    "print(\"Preprocessed Holdout Dataset Shape:\", holdout_data.shape)\n",
    "\n",
    "# Let's see what columns we have after preprocessing\n",
    "print(\"\\nFirst few columns of preprocessed data:\")\n",
    "print(train_data.columns[:10].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Sub-task 4.\n",
    "\n",
    "Select important variables using the LASSO_LARS linear regression method, going through all possible model complexities within your method and selecting the best one by cross-validation with 5 blocks and MSE as a criterion. In stepwise regression methods, use R-square, p-\n",
    "value or AIC at your discretion to stop and select the next step. Plot a graph of the CV-MSE dependence on complexity (the number of variables or the number of components in the model), a graph of the trace of standardized\n",
    "coefficients on complexity. In these graphs, mark the best model complexity by CV with a vertical line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Feature Selection with LASSO_LARS (Fixed)\n",
    "\n",
    "# Define function to convert all remaining categorical features to numeric using one-hot encoding\n",
    "def prepare_data_for_model(df, target_col=\"TargetD\"):\n",
    "    # Separate target and features\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Get all transformed features and binary indicators\n",
    "    transformed_features = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if \"_bc\" in col\n",
    "        or \"_target_enc\" in col\n",
    "        or \"_threshold_enc\" in col\n",
    "        or \"_missing\" in col\n",
    "    ]\n",
    "\n",
    "    # Get remaining numeric features (exclude target and bins)\n",
    "    remaining_numeric = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if df[col].dtype in [\"int64\", \"float64\"]\n",
    "        and col not in [\"TargetB\", \"TargetD\", \"TargetD_bins\", \"ID\"]\n",
    "        and col not in transformed_features\n",
    "    ]\n",
    "\n",
    "    # Combine all features\n",
    "    all_features = transformed_features + remaining_numeric\n",
    "    X = df[all_features]\n",
    "\n",
    "    return X, y, all_features\n",
    "\n",
    "\n",
    "# Prepare data for the model\n",
    "X_train, y_train, feature_names = prepare_data_for_model(train_data)\n",
    "X_holdout, y_holdout, _ = prepare_data_for_model(holdout_data)\n",
    "\n",
    "print(f\"Number of features for modeling: {len(feature_names)}\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_holdout_scaled = scaler.transform(X_holdout)\n",
    "\n",
    "# Initialize and fit the LASSO_LARS model with cross-validation\n",
    "# We'll use LassoLarsCV which automatically performs CV to select the best alpha\n",
    "lasso_lars_cv = LassoLarsCV(cv=5, max_iter=1000)\n",
    "lasso_lars_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best complexity (number of non-zero coefficients)\n",
    "best_complexity = np.sum(lasso_lars_cv.coef_ != 0)\n",
    "print(f\"Best model complexity based on CV: {best_complexity} features\")\n",
    "\n",
    "# Let's take a different approach to analyze complexity vs. MSE\n",
    "# Using LassoLars directly with different alphas\n",
    "alphas = np.logspace(-6, 2, 40)  # Generate a range of alphas\n",
    "complexities = []\n",
    "cv_mse_values = []\n",
    "\n",
    "# For each alpha value, fit a model and calculate the complexity and cross-validation MSE\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = LassoLars(alpha=alpha, max_iter=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Calculate complexity (number of non-zero coefficients)\n",
    "    complexity = np.sum(model.coef_ != 0)\n",
    "    complexities.append(complexity)\n",
    "\n",
    "    # Calculate cross-validation MSE\n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train_scaled, y_train, cv=5, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "    cv_mse = -np.mean(cv_scores)  # Convert negative MSE back to positive\n",
    "    cv_mse_values.append(cv_mse)\n",
    "\n",
    "# Print dimensions to verify\n",
    "print(f\"Length of complexities: {len(complexities)}\")\n",
    "print(f\"Length of cv_mse_values: {len(cv_mse_values)}\")\n",
    "\n",
    "# Now plot MSE vs. complexity\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(complexities, cv_mse_values, marker=\"o\", alpha=0.7)\n",
    "\n",
    "# Instead of using spline interpolation, let's use a simpler approach to show trends\n",
    "# Group by complexity and average the MSE values\n",
    "unique_complexities = sorted(set(complexities))\n",
    "average_mse = []\n",
    "\n",
    "for complexity in unique_complexities:\n",
    "    indices = [i for i, c in enumerate(complexities) if c == complexity]\n",
    "    avg_mse = np.mean([cv_mse_values[i] for i in indices])\n",
    "    average_mse.append(avg_mse)\n",
    "\n",
    "# Plot the average MSE per complexity\n",
    "plt.plot(\n",
    "    unique_complexities, average_mse, \"r-\", alpha=0.7, linewidth=2, label=\"Avg MSE\"\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    x=best_complexity,\n",
    "    color=\"g\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Best Complexity: {best_complexity}\",\n",
    ")\n",
    "plt.xlabel(\"Model Complexity (Number of Features)\")\n",
    "plt.ylabel(\"Cross-Validation MSE\")\n",
    "plt.title(\"CV-MSE vs. Model Complexity\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot coefficient values vs alpha for the most important features\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Identify the top features based on absolute coefficient values\n",
    "best_model = LassoLars(alpha=lasso_lars_cv.alpha_)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "top_feature_indices = np.argsort(np.abs(best_model.coef_))[\n",
    "    -10:\n",
    "]  # Get indices of top 10 features\n",
    "\n",
    "# Create a colormap for features\n",
    "\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(top_feature_indices)))\n",
    "\n",
    "# Plot coefficient trajectories\n",
    "for i, feature_idx in enumerate(top_feature_indices):\n",
    "    feature_name = feature_names[feature_idx]\n",
    "    coef_values = []\n",
    "\n",
    "    for alpha in alphas:\n",
    "        model = LassoLars(alpha=alpha)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        coef_values.append(model.coef_[feature_idx])\n",
    "\n",
    "    plt.plot(\n",
    "        alphas, coef_values, label=feature_name, color=colors[i], linewidth=2, alpha=0.7\n",
    "    )\n",
    "\n",
    "plt.axvline(\n",
    "    x=lasso_lars_cv.alpha_,\n",
    "    color=\"k\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Best Alpha: {lasso_lars_cv.alpha_:.5f}\",\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Alpha (Regularization Parameter)\")\n",
    "plt.ylabel(\"Coefficient Values\")\n",
    "plt.title(\"Top Feature Coefficients vs. Alpha\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(loc=\"best\", fontsize=\"small\")\n",
    "plt.show()\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_features_idx = np.where(lasso_lars_cv.coef_ != 0)[0]\n",
    "selected_features = [feature_names[i] for i in selected_features_idx]\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features:\")\n",
    "for feature in selected_features:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "# Prepare the data with only the selected features\n",
    "X_train_selected = X_train_scaled[:, selected_features_idx]\n",
    "X_holdout_selected = X_holdout_scaled[:, selected_features_idx]\n",
    "\n",
    "# Also create unscaled versions for later use with other models\n",
    "X_train_selected_unscaled = X_train.iloc[:, selected_features_idx].values\n",
    "X_holdout_selected_unscaled = X_holdout.iloc[:, selected_features_idx].values\n",
    "\n",
    "# Train a linear regression model using the selected features\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Calculate R-squared and MSE on both training and holdout sets\n",
    "train_r2 = linear_model.score(X_train_selected, y_train)\n",
    "holdout_r2 = linear_model.score(X_holdout_selected, y_holdout)\n",
    "\n",
    "train_predictions = linear_model.predict(X_train_selected)\n",
    "holdout_predictions = linear_model.predict(X_holdout_selected)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_predictions)\n",
    "holdout_mse = mean_squared_error(y_holdout, holdout_predictions)\n",
    "\n",
    "print(f\"Training R-squared: {train_r2:.4f}\")\n",
    "print(f\"Holdout R-squared: {holdout_r2:.4f}\")\n",
    "print(f\"Training MSE: {train_mse:.2f}\")\n",
    "print(f\"Holdout MSE: {holdout_mse:.2f}\")\n",
    "\n",
    "# Calculate the out-of-bag (OOB) error using CV\n",
    "\n",
    "\n",
    "def calculate_oob_error(model, X, y, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    oob_predictions = np.zeros_like(y)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_cv_train, X_cv_test = X[train_idx], X[test_idx]\n",
    "        y_cv_train = y.iloc[train_idx] if hasattr(y, \"iloc\") else y[train_idx]\n",
    "\n",
    "        model.fit(X_cv_train, y_cv_train)\n",
    "        oob_predictions[test_idx] = model.predict(X_cv_test)\n",
    "\n",
    "    return mean_squared_error(y, oob_predictions)\n",
    "\n",
    "\n",
    "# Calculate OOB error for the linear model\n",
    "mean_oob_error = calculate_oob_error(LinearRegression(), X_train_selected, y_train)\n",
    "print(f\"Out-of-bag MSE: {mean_oob_error:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Sub-task 5.\n",
    "\n",
    "For the best selected complexity of the linear model, using bootstrapping (100 bootstrap\n",
    "samples of 25% of the original size), plot histograms (or kde approximation)\n",
    "of the distribution of the bias constant in the resulting regression equation (constant b\n",
    "if regression y=ax+b) indicating the mean value and 95% interval on the graph.\n",
    "Similarly, estimate the OOB error MSE. How does it compare with the best cross-validation\n",
    "error and the error on the test part of the sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform bootstrapping to estimate bias constant and OOB error\n",
    "n_bootstrap = 100\n",
    "bootstrap_size = int(0.25 * X_train_selected.shape[0])  # 25% of the original size\n",
    "bootstrap_intercepts = []\n",
    "bootstrap_oob_errors = []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    # Sample with replacement\n",
    "    bootstrap_indices = np.random.choice(\n",
    "        X_train_selected.shape[0], size=bootstrap_size, replace=True\n",
    "    )\n",
    "\n",
    "    # Identify OOB (out-of-bag) samples\n",
    "    oob_indices = np.array(\n",
    "        [i for i in range(X_train_selected.shape[0]) if i not in bootstrap_indices]\n",
    "    )\n",
    "\n",
    "    # Training data for this bootstrap sample\n",
    "    X_bootstrap = X_train_selected[bootstrap_indices]\n",
    "    y_bootstrap = y_train.iloc[bootstrap_indices]\n",
    "\n",
    "    # OOB data\n",
    "    X_oob = X_train_selected[oob_indices]\n",
    "    y_oob = y_train.iloc[oob_indices]\n",
    "\n",
    "    # Train the model on the bootstrap sample\n",
    "    bootstrap_model = LinearRegression()\n",
    "    bootstrap_model.fit(X_bootstrap, y_bootstrap)\n",
    "\n",
    "    # Store the intercept (bias constant)\n",
    "    bootstrap_intercepts.append(bootstrap_model.intercept_)\n",
    "\n",
    "    # Evaluate on OOB samples and store the MSE\n",
    "    if len(oob_indices) > 0:  # Make sure there are OOB samples\n",
    "        oob_predictions = bootstrap_model.predict(X_oob)\n",
    "        oob_mse = mean_squared_error(y_oob, oob_predictions)\n",
    "        bootstrap_oob_errors.append(oob_mse)\n",
    "\n",
    "# Calculate mean and 95% confidence interval for the intercept\n",
    "mean_intercept = np.mean(bootstrap_intercepts)\n",
    "ci_lower = np.percentile(bootstrap_intercepts, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_intercepts, 97.5)\n",
    "\n",
    "# Calculate mean OOB error\n",
    "mean_oob_error = np.mean(bootstrap_oob_errors)\n",
    "\n",
    "# Plot the histogram of bootstrap intercepts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(bootstrap_intercepts, bins=30, alpha=0.7, color=\"skyblue\", density=True)\n",
    "plt.axvline(\n",
    "    mean_intercept, color=\"red\", linestyle=\"--\", label=f\"Mean: {mean_intercept:.2f}\"\n",
    ")\n",
    "plt.axvline(\n",
    "    ci_lower, color=\"green\", linestyle=\":\", label=f\"95% CI Lower: {ci_lower:.2f}\"\n",
    ")\n",
    "plt.axvline(\n",
    "    ci_upper, color=\"green\", linestyle=\":\", label=f\"95% CI Upper: {ci_upper:.2f}\"\n",
    ")\n",
    "plt.title(\"Distribution of Regression Intercept (Bias Constant)\")\n",
    "plt.xlabel(\"Intercept Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compare OOB error with CV error and holdout error\n",
    "cv_error = lasso_lars_cv.mse_path_.mean(axis=1)[\n",
    "    np.argmin(lasso_lars_cv.mse_path_.mean(axis=1))\n",
    "]\n",
    "holdout_mse = mean_squared_error(y_holdout, holdout_predictions)\n",
    "\n",
    "print(f\"Bootstrap OOB MSE: {mean_oob_error:.2f}\")\n",
    "print(f\"Cross-Validation MSE: {cv_error:.2f}\")\n",
    "print(f\"Holdout MSE: {holdout_mse:.2f}\")\n",
    "print(f\"Training MSE: {train_mse:.2f}\")\n",
    "\n",
    "# Additional analysis - Compare OOB error distribution with CV error\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(bootstrap_oob_errors, bins=30, alpha=0.7, color=\"skyblue\", density=True)\n",
    "plt.axvline(\n",
    "    mean_oob_error,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean OOB MSE: {mean_oob_error:.2f}\",\n",
    ")\n",
    "plt.axvline(cv_error, color=\"green\", linestyle=\":\", label=f\"CV MSE: {cv_error:.2f}\")\n",
    "plt.axvline(\n",
    "    holdout_mse, color=\"purple\", linestyle=\"-.\", label=f\"Holdout MSE: {holdout_mse:.2f}\"\n",
    ")\n",
    "plt.title(\"Distribution of OOB Mean Squared Error\")\n",
    "plt.xlabel(\"MSE\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Sub-task 6.\n",
    "\n",
    "Use the selected variables to build a nonlinear model for predicting the numerical response using the Poly Regression method, while selecting metaparameters using the HalvingRandomSearchCV method. Note:\n",
    "- In PLS regressions, use VIP statistics with any threshold in the range [0.5,1] to select variables (after selecting the number of components by cross-validation).\n",
    "- Note that categorical variables can be either included in the model in their entirety (with all levels) or not.\n",
    "- For single-layer MLP, you can vary the number of neurons and the regularization constant,\n",
    "for Poisson Regression, Gamma Regression, and polynomial ridge regression - the regularization constant and the degree of the polynomial (for Gamma and Poisson, use\n",
    "PolynomialFeatures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the selected features to build nonlinear models\n",
    "# First, prepare unscaled features for the model\n",
    "X_train_selected_unscaled = X_train.values[:, selected_features_idx]\n",
    "X_holdout_selected_unscaled = X_holdout.values[:, selected_features_idx]\n",
    "\n",
    "# Polynomial Regression with Ridge Regularization\n",
    "poly_ridge_params = {\n",
    "    \"polynomialfeatures__degree\": [2, 3],\n",
    "    \"ridge__alpha\": np.logspace(-3, 3, 10),\n",
    "}\n",
    "\n",
    "poly_ridge_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"polynomialfeatures\", PolynomialFeatures()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge(random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Use HalvingRandomSearchCV for hyperparameter tuning\n",
    "halving_cv_poly = HalvingRandomSearchCV(\n",
    "    poly_ridge_pipeline,\n",
    "    poly_ridge_params,\n",
    "    cv=5,\n",
    "    factor=2,  # Reduce candidates by half each iteration\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "halving_cv_poly.fit(X_train_selected_unscaled, y_train)\n",
    "\n",
    "# Get best parameters and score\n",
    "best_params_poly = halving_cv_poly.best_params_\n",
    "best_score_poly = halving_cv_poly.best_score_\n",
    "\n",
    "print(\"Polynomial Ridge Regression:\")\n",
    "print(f\"Best Parameters: {best_params_poly}\")\n",
    "print(f\"Best CV Score (negative MSE): {best_score_poly}\")\n",
    "\n",
    "# Evaluate the model on the holdout set\n",
    "holdout_predictions = halving_cv_poly.predict(X_holdout_selected_unscaled)\n",
    "holdout_mse_nonlinear = mean_squared_error(y_holdout, holdout_predictions)\n",
    "holdout_r2_nonlinear = r2_score(y_holdout, holdout_predictions)\n",
    "\n",
    "print(f\"Holdout MSE for Nonlinear Model: {holdout_mse_nonlinear:.2f}\")\n",
    "print(f\"Holdout R-squared for Nonlinear Model: {holdout_r2_nonlinear:.2f}\")\n",
    "\n",
    "# Compare with the linear model\n",
    "print(f\"Holdout MSE for Linear Model: {holdout_mse:.2f}\")\n",
    "print(f\"Holdout R-squared for Linear Model: {holdout_r2:.2f}\")\n",
    "\n",
    "# Calculate OOB error for the nonlinear model using bootstrapping\n",
    "bootstrap_oob_errors_nonlinear = []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    # Sample with replacement\n",
    "    bootstrap_indices = np.random.choice(\n",
    "        X_train_selected_unscaled.shape[0], size=bootstrap_size, replace=True\n",
    "    )\n",
    "\n",
    "    # Identify OOB samples\n",
    "    oob_indices = np.array(\n",
    "        [\n",
    "            i\n",
    "            for i in range(X_train_selected_unscaled.shape[0])\n",
    "            if i not in bootstrap_indices\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # OOB data\n",
    "    X_oob = X_train_selected_unscaled[oob_indices]\n",
    "    y_oob = y_train.iloc[oob_indices]\n",
    "\n",
    "    # Evaluate on OOB samples and store the MSE\n",
    "    if len(oob_indices) > 0:\n",
    "        oob_predictions = halving_cv_poly.predict(X_oob)\n",
    "        oob_mse = mean_squared_error(y_oob, oob_predictions)\n",
    "        bootstrap_oob_errors_nonlinear.append(oob_mse)\n",
    "\n",
    "# Calculate mean OOB error for the nonlinear model\n",
    "mean_oob_error_nonlinear = np.mean(bootstrap_oob_errors_nonlinear)\n",
    "\n",
    "print(f\"Bootstrap OOB MSE for Nonlinear Model: {mean_oob_error_nonlinear:.2f}\")\n",
    "print(f\"Bootstrap OOB MSE for Linear Model: {mean_oob_error:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Sub-task 7.\n",
    "\n",
    "Plot a graph - a \"lattice\" of metaparameter enumeration, indicating the quality of the models with color, and the number of repetitions for halving with the size of the dots). Compare the CV, OOB and holdout of the quality assessment of the obtained linear and nonlinear models, what conclusions can be drawn from this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results from the HalvingRandomSearchCV object for visualization\n",
    "def extract_param_results(halving_cv, param_names):\n",
    "    # Get results from all iterations\n",
    "    results = pd.DataFrame(halving_cv.cv_results_)\n",
    "\n",
    "    # Extract parameter values and scores\n",
    "    param_values = {}\n",
    "    for param in param_names:\n",
    "        param_values[param] = results[f\"param_{param}\"].values\n",
    "\n",
    "    scores = results[\"mean_test_score\"].values\n",
    "    n_resources = results[\"n_resources\"].values\n",
    "\n",
    "    return param_values, scores, n_resources\n",
    "\n",
    "\n",
    "# Create the lattice visualization\n",
    "def plot_param_lattice(halving_cv, param_names, title):\n",
    "    param_values, scores, n_resources = extract_param_results(halving_cv, param_names)\n",
    "\n",
    "    # Create a DataFrame for plotting\n",
    "    plot_data = pd.DataFrame(\n",
    "        {\n",
    "            param_names[0]: param_values[param_names[0]],\n",
    "            param_names[1]: param_values[param_names[1]],\n",
    "            \"score\": scores,\n",
    "            \"n_resources\": n_resources,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Convert scores to positive values (since CV returns negative MSE)\n",
    "    if np.all(plot_data[\"score\"] < 0):\n",
    "        plot_data[\"score\"] = -plot_data[\"score\"]\n",
    "\n",
    "    # Create the lattice plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Create a scatter plot with color representing score and size representing n_resources\n",
    "    scatter = plt.scatter(\n",
    "        x=plot_data[param_names[0]],\n",
    "        y=plot_data[param_names[1]],\n",
    "        c=plot_data[\"score\"],\n",
    "        s=plot_data[\"n_resources\"] / 10,  # Scale down the size for better visualization\n",
    "        cmap=\"viridis_r\",  # Reversed colormap so darker colors = better scores\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    # Add a colorbar\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label(\"Mean Test Score (MSE)\")\n",
    "\n",
    "    # Add a legend for the size of points\n",
    "    unique_resources = sorted(plot_data[\"n_resources\"].unique())\n",
    "    handles = [\n",
    "        plt.scatter([], [], s=n / 10, color=\"gray\", alpha=0.7) for n in unique_resources\n",
    "    ]\n",
    "    labels = [f\"n_resources: {int(n)}\" for n in unique_resources]\n",
    "    plt.legend(handles, labels, title=\"Halving Iterations\", loc=\"upper right\")\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(param_names[0])\n",
    "    plt.ylabel(param_names[1])\n",
    "    plt.title(title)\n",
    "\n",
    "    # If the parameter is ridge__alpha, use log scale for axis\n",
    "    if param_names[1] == \"ridge__alpha\":\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create the lattice plot for Polynomial Ridge\n",
    "plot_param_lattice(\n",
    "    halving_cv_poly,\n",
    "    [\"polynomialfeatures__degree\", \"ridge__alpha\"],\n",
    "    \"Polynomial Ridge Regression: Metaparameter Lattice\",\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on various metrics including CV, training and holdout sets\n",
    "def calculate_oob_error(model, X, y, cv=5):\n",
    "    \"\"\"Calculate out-of-bag error using cross-validation\"\"\"\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    oob_predictions = np.zeros_like(y)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_cv_train, X_cv_test = X[train_idx], X[test_idx]\n",
    "        y_cv_train = y[train_idx]\n",
    "\n",
    "        # Fit the model on training data\n",
    "        model.fit(X_cv_train, y_cv_train)\n",
    "        # Predict on test data\n",
    "        oob_predictions[test_idx] = model.predict(X_cv_test)\n",
    "\n",
    "    # Calculate MSE\n",
    "    return mean_squared_error(y, oob_predictions)\n",
    "\n",
    "\n",
    "# Get the best polynomial ridge model\n",
    "best_poly_ridge = halving_cv_poly.best_estimator_\n",
    "\n",
    "# Compute performance metrics\n",
    "# Cross-validation MSE (from the search)\n",
    "cv_mse_poly = -halving_cv_poly.best_score_\n",
    "\n",
    "# Training set performance\n",
    "y_train_pred_poly = best_poly_ridge.predict(X_train_selected_unscaled)\n",
    "train_mse_poly = mean_squared_error(y_train, y_train_pred_poly)\n",
    "train_r2_poly = r2_score(y_train, y_train_pred_poly)\n",
    "\n",
    "# Holdout set performance\n",
    "y_holdout_pred_poly = best_poly_ridge.predict(X_holdout_selected_unscaled)\n",
    "holdout_mse_poly = mean_squared_error(y_holdout, y_holdout_pred_poly)\n",
    "holdout_r2_poly = r2_score(y_holdout, y_holdout_pred_poly)\n",
    "\n",
    "# Out-of-bag error using the best model configuration\n",
    "oob_mse_poly = calculate_oob_error(\n",
    "    Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"polynomialfeatures\",\n",
    "                PolynomialFeatures(\n",
    "                    degree=halving_cv_poly.best_params_[\"polynomialfeatures__degree\"],\n",
    "                    include_bias=False,\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"ridge\",\n",
    "                Ridge(\n",
    "                    alpha=halving_cv_poly.best_params_[\"ridge__alpha\"], random_state=42\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    X_train_selected_unscaled,\n",
    "    y_train.values if hasattr(y_train, \"values\") else y_train,\n",
    ")\n",
    "\n",
    "# Also calculate metrics for the linear model (from previous tasks) for comparison\n",
    "# Ensure we have numpy arrays\n",
    "y_train_array = y_train.values if hasattr(y_train, \"values\") else y_train\n",
    "y_holdout_array = y_holdout.values if hasattr(y_holdout, \"values\") else y_holdout\n",
    "\n",
    "# Linear model predictions\n",
    "linear_train_pred = linear_model.predict(X_train_selected)\n",
    "linear_holdout_pred = linear_model.predict(X_holdout_selected)\n",
    "\n",
    "# Linear model metrics\n",
    "linear_train_mse = mean_squared_error(y_train_array, linear_train_pred)\n",
    "linear_holdout_mse = mean_squared_error(y_holdout_array, linear_holdout_pred)\n",
    "linear_train_r2 = r2_score(y_train_array, linear_train_pred)\n",
    "linear_holdout_r2 = r2_score(y_holdout_array, linear_holdout_pred)\n",
    "\n",
    "# OOB error for linear model\n",
    "linear_oob_mse = calculate_oob_error(\n",
    "    LinearRegression(), X_train_selected, y_train_array\n",
    ")\n",
    "\n",
    "# Print results in a nice formatted table\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(f\"{'Metric':<20} {'Linear Model':<15} {'Polynomial Ridge':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'CV MSE':<20} {cv_error:<15.4f} {cv_mse_poly:<15.4f}\")\n",
    "print(f\"{'OOB MSE':<20} {linear_oob_mse:<15.4f} {oob_mse_poly:<15.4f}\")\n",
    "print(f\"{'Training MSE':<20} {linear_train_mse:<15.4f} {train_mse_poly:<15.4f}\")\n",
    "print(f\"{'Holdout MSE':<20} {linear_holdout_mse:<15.4f} {holdout_mse_poly:<15.4f}\")\n",
    "print(f\"{'Training R²':<20} {linear_train_r2:<15.4f} {train_r2_poly:<15.4f}\")\n",
    "print(f\"{'Holdout R²':<20} {linear_holdout_r2:<15.4f} {holdout_r2_poly:<15.4f}\")\n",
    "\n",
    "# Create visual comparison of metrics\n",
    "metrics = [\"CV MSE\", \"OOB MSE\", \"Training MSE\", \"Holdout MSE\"]\n",
    "linear_values = [cv_error, linear_oob_mse, linear_train_mse, linear_holdout_mse]\n",
    "poly_values = [cv_mse_poly, oob_mse_poly, train_mse_poly, holdout_mse_poly]\n",
    "\n",
    "# Bar chart comparing MSE metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width / 2, linear_values, width, label=\"Linear Model\")\n",
    "plt.bar(x + width / 2, poly_values, width, label=\"Polynomial Ridge\")\n",
    "\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.title(\"MSE Comparison: Linear vs Polynomial Ridge\")\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add values on top of bars\n",
    "for i, v in enumerate(linear_values):\n",
    "    plt.text(i - width / 2, v + 0.1, f\"{v:.2f}\", ha=\"center\")\n",
    "for i, v in enumerate(poly_values):\n",
    "    plt.text(i + width / 2, v + 0.1, f\"{v:.2f}\", ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# R-squared comparison\n",
    "metrics_r2 = [\"Training R²\", \"Holdout R²\"]\n",
    "linear_r2_values = [linear_train_r2, linear_holdout_r2]\n",
    "poly_r2_values = [train_r2_poly, holdout_r2_poly]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "x_r2 = np.arange(len(metrics_r2))\n",
    "\n",
    "plt.bar(x_r2 - width / 2, linear_r2_values, width, label=\"Linear Model\")\n",
    "plt.bar(x_r2 + width / 2, poly_r2_values, width, label=\"Polynomial Ridge\")\n",
    "\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"R-squared\")\n",
    "plt.title(\"R-squared Comparison: Linear vs Polynomial Ridge\")\n",
    "plt.xticks(x_r2, metrics_r2)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add values on top of bars\n",
    "for i, v in enumerate(linear_r2_values):\n",
    "    plt.text(i - width / 2, v + 0.01, f\"{v:.4f}\", ha=\"center\")\n",
    "for i, v in enumerate(poly_r2_values):\n",
    "    plt.text(i + width / 2, v + 0.01, f\"{v:.4f}\", ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals for both models\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Linear model residuals\n",
    "plt.subplot(1, 2, 1)\n",
    "linear_residuals = y_holdout_array - linear_holdout_pred\n",
    "plt.scatter(linear_holdout_pred, linear_residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Linear Model: Residual Plot\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Polynomial Ridge residuals\n",
    "plt.subplot(1, 2, 2)\n",
    "poly_residuals = y_holdout_array - y_holdout_pred_poly\n",
    "plt.scatter(y_holdout_pred_poly, poly_residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Polynomial Ridge: Residual Plot\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Conclusions\n",
    "print(\"\\nConclusions:\")\n",
    "print(\"1. Comparison of CV, OOB, and Holdout Metrics:\")\n",
    "if cv_mse_poly < cv_error:\n",
    "    print(\n",
    "        \"   - The Polynomial Ridge model shows better cross-validation performance than the linear model.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"   - The linear model shows better cross-validation performance than the Polynomial Ridge model.\"\n",
    "    )\n",
    "\n",
    "if oob_mse_poly < linear_oob_mse:\n",
    "    print(\n",
    "        \"   - The Polynomial Ridge model shows better out-of-bag performance than the linear model.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"   - The linear model shows better out-of-bag performance than the Polynomial Ridge model.\"\n",
    "    )\n",
    "\n",
    "if holdout_mse_poly < linear_holdout_mse:\n",
    "    print(\n",
    "        \"   - The Polynomial Ridge model generalizes better to the holdout set than the linear model.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"   - The linear model generalizes better to the holdout set than the Polynomial Ridge model.\"\n",
    "    )\n",
    "\n",
    "# Check for overfitting\n",
    "linear_diff = abs(linear_holdout_mse - linear_train_mse)\n",
    "poly_diff = abs(holdout_mse_poly - train_mse_poly)\n",
    "\n",
    "print(\"\\n2. Overfitting Analysis:\")\n",
    "if poly_diff > linear_diff:\n",
    "    print(\n",
    "        f\"   - The Polynomial Ridge model shows more evidence of overfitting with a train-holdout MSE difference of {poly_diff:.4f}.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - The linear model has a train-holdout MSE difference of {linear_diff:.4f}.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"   - The linear model shows more evidence of overfitting with a train-holdout MSE difference of {linear_diff:.4f}.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - The Polynomial Ridge model has a train-holdout MSE difference of {poly_diff:.4f}.\"\n",
    "    )\n",
    "print(\"\\n3. Best Model Based on Performance Metrics:\")\n",
    "if holdout_mse_poly < linear_holdout_mse and holdout_r2_poly > linear_holdout_r2:\n",
    "    print(\n",
    "        f\"   - The Polynomial Ridge model performs better overall with a holdout MSE of {holdout_mse_poly:.4f} and R² of {holdout_r2_poly:.4f}.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - Best parameters: Polynomial degree = {halving_cv_poly.best_params_['polynomialfeatures__degree']}, Alpha = {halving_cv_poly.best_params_['ridge__alpha']:.4f}\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"   - The linear model performs better overall with a holdout MSE of {linear_holdout_mse:.4f} and R² of {linear_holdout_r2:.4f}.\"\n",
    "    )\n",
    "\n",
    "print(\"\\n4. Metaparameter Lattice Analysis:\")\n",
    "print(\n",
    "    \"   - The lattice visualization shows how model performance varies with different combinations of polynomial degree and regularization strength.\"\n",
    ")\n",
    "print(\"   - Darker colors in the plot represent better model performance (lower MSE).\")\n",
    "print(\n",
    "    \"   - Larger points represent configurations that survived to later rounds of the halving search.\"\n",
    ")\n",
    "print(\n",
    "    f\"   - The optimal configuration found was a polynomial of degree {halving_cv_poly.best_params_['polynomialfeatures__degree']} with alpha = {halving_cv_poly.best_params_['ridge__alpha']:.4f}.\"\n",
    ")\n",
    "\n",
    "print(\"\\n5. Evaluation Methods Comparison:\")\n",
    "print(\n",
    "    \"   - Cross-validation provides a robust estimate of model performance by averaging over multiple train-test splits.\"\n",
    ")\n",
    "print(\n",
    "    \"   - Out-of-bag error gives an unbiased estimate of generalization performance without using a dedicated test set.\"\n",
    ")\n",
    "print(\n",
    "    \"   - Holdout evaluation gives a final assessment of how well the model will perform on completely unseen data.\"\n",
    ")\n",
    "\n",
    "cv_oob_diff_linear = abs(cv_error - linear_oob_mse)\n",
    "cv_oob_diff_poly = abs(cv_mse_poly - oob_mse_poly)\n",
    "\n",
    "if cv_oob_diff_linear < cv_oob_diff_poly:\n",
    "    print(\n",
    "        f\"   - The linear model shows more consistency between CV and OOB metrics (difference: {cv_oob_diff_linear:.4f})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - The Polynomial Ridge model shows a difference of {cv_oob_diff_poly:.4f} between CV and OOB metrics\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"   - The Polynomial Ridge model shows more consistency between CV and OOB metrics (difference: {cv_oob_diff_poly:.4f})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - The linear model shows a difference of {cv_oob_diff_linear:.4f} between CV and OOB metrics\"\n",
    "    )\n",
    "\n",
    "cv_holdout_diff_linear = abs(cv_error - linear_holdout_mse)\n",
    "cv_holdout_diff_poly = abs(cv_mse_poly - holdout_mse_poly)\n",
    "\n",
    "if cv_holdout_diff_linear < cv_holdout_diff_poly:\n",
    "    print(\n",
    "        f\"   - The linear model shows more consistency between CV and holdout metrics (difference: {cv_holdout_diff_linear:.4f})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - The Polynomial Ridge model shows a difference of {cv_holdout_diff_poly:.4f} between CV and holdout metrics\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"   - The Polynomial Ridge model shows more consistency between CV and holdout metrics (difference: {cv_holdout_diff_poly:.4f})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - The linear model shows a difference of {cv_holdout_diff_linear:.4f} between CV and holdout metrics\"\n",
    "    )\n",
    "\n",
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Linear model predictions vs actual\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_holdout_array, linear_holdout_pred, alpha=0.5)\n",
    "plt.plot(\n",
    "    [min(y_holdout_array), max(y_holdout_array)],\n",
    "    [min(y_holdout_array), max(y_holdout_array)],\n",
    "    \"r--\",\n",
    ")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Linear Model: Actual vs Predicted\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Polynomial Ridge predictions vs actual\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_holdout_array, y_holdout_pred_poly, alpha=0.5)\n",
    "plt.plot(\n",
    "    [min(y_holdout_array), max(y_holdout_array)],\n",
    "    [min(y_holdout_array), max(y_holdout_array)],\n",
    "    \"r--\",\n",
    ")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Polynomial Ridge: Actual vs Predicted\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Final summary\n",
    "print(\"\\nFinal Summary:\")\n",
    "if holdout_mse_poly < linear_holdout_mse:\n",
    "    print(\n",
    "        f\"The Polynomial Ridge model (degree={halving_cv_poly.best_params_['polynomialfeatures__degree']}, alpha={halving_cv_poly.best_params_['ridge__alpha']:.4f}) outperforms the linear model.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"It achieved a {(1 - holdout_mse_poly/linear_holdout_mse)*100:.2f}% reduction in MSE on the holdout set.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"The improvement in R² is {(holdout_r2_poly - linear_holdout_r2)*100:.2f} percentage points.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"The linear model outperforms the Polynomial Ridge model, suggesting that:\")\n",
    "    print(\"1. The relationship between features and target may be predominantly linear\")\n",
    "    print(\"2. The added complexity of polynomial features may be causing overfitting\")\n",
    "    print(\n",
    "        \"3. The additional parameters in the polynomial model may not be capturing meaningful patterns\"\n",
    "    )\n",
    "\n",
    "print(\"\\nRecommendation:\")\n",
    "if holdout_mse_poly < linear_holdout_mse and (train_mse_poly - holdout_mse_poly) < 1.0:\n",
    "    print(\n",
    "        \"Use the Polynomial Ridge model for future predictions due to its superior performance and reasonable generalization.\"\n",
    "    )\n",
    "elif (\n",
    "    holdout_mse_poly < linear_holdout_mse and (train_mse_poly - holdout_mse_poly) >= 1.0\n",
    "):\n",
    "    print(\n",
    "        \"The Polynomial Ridge model performs better but shows signs of overfitting. Consider:\"\n",
    "    )\n",
    "    print(\"1. Collecting more training data\")\n",
    "    print(\"2. Using a stronger regularization parameter\")\n",
    "    print(\"3. Reducing the polynomial degree\")\n",
    "else:\n",
    "    print(\n",
    "        \"Prefer the linear model for its simplicity and better generalization to unseen data.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
